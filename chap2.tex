%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                 %
%                            CHAPTER TWO                          %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{ARRAY-BASED MESH REPRESENTATIONS}
\label{chap:struct}

This Chapter presents two data structures, each used to represent
the portion of the mesh (a.k.a. \emph{mesh part}) stored in one
shared memory space.
Each of these structures are augmented with information connecting multiple
mesh parts across distributed memory spaces as described in
Chapter \ref{chap:parallel}, the result of which is a pair of fully parallel
mesh data structures.

\section{Goals}
\label{sec:struct_goals}

{\bf These goals are from the SISC paper in review, will
need to be attributed}

An unstructured mesh simulation code relies heavily on
multiple core capabilities to deal with the mesh,
and the range of features available at this level constrain
the capabilities of the simulation as a whole.
As such, the long-term goal towards which this thesis
contributes is the development of a mesh data structure
with the following capabilities:

\begin{enumerate}
\item The flexibility to adapt to evolving meshes
\item The ability to represent any of the conforming meshes typically
used by Finite Element (FE) and Finite Volume (FV) methods
\item Low memory use
\item High locality of storage
\item Highly scalable implementation for distributed memory computers
\item The ability to parallelize work inside heterogeneous
supercomputer nodes
\end{enumerate}

The first goal is the most consequential.
If adaptivity is implemented as a series of requests to
add and remove mesh entities, then a much more complex structure is required
(see Section \ref{sec:def_adapt} for further discussion).
Such a structure is described in Section \ref{sec:sisc}.
However, this approach tends to conflict with our sixth goal regarding
on-node parallelism.
Therefore we also present an alternative
approach in which the additions and removals required for adaptivity
are accumulated into batches to be applied all at once
(see Section \ref{sec:indset}), which allows us to use a less complex structure
as presented in Section \ref{sec:omega_h-struct} while adhering to the
principles of on-node programming established in Sections
\ref{sec:openmp} and \ref{sec:cuda}.

\section{Related Work}

{\bf SISC attribution.}

There are several other implementations of mesh data structures
which offer various subsets of the features described herein:

First, there are dynamic structures which support mesh adaptation.
FMDB is an object-oriented structure that
stores full one-level representations \cite{seol2006efficient}.
It is capable of constant-time local
mesh modifications and supporting adaptation code.
Similar to FMDB is the mesh databased used by Comp\`{e}re and Remacle
in the MAdLib adaptation package \cite{compere2010mesh}.
Celes, Paulino, and Espinha also implement a structure capable of
adaptation \cite{celes2005compact}.
Another example of an adaptive structure
is the GRUMMP system developed by Ollivier-Gooch
and available at \texttt{http://tetra.mech.ubc.ca/GRUMMP}.

Second, there are array-based structures designed for
efficient access of unchanging meshes.
STK is an array-based mesh structure being developed at
Sandia National Laboratory \cite{edwards2010sierra}.
MOAB is another array-based structure developed primarily
at Argonne National Laboratory \cite{tautges_moab:_2004},
and working with MOAB an Adjacent Half-Facet structure
was implemented which can perform some modifications \cite{dyedov2014ahf}.

\section{Choices in Representation}

There are key choices in terms of which entities
and adjacencies to store which apply equally well
to both of the structures presented in this Chapter.

\subsection{Choosing Entities to Store}

Unstructured mesh applications must represent
the portions of the mesh topology graph
needed to support the operations carried out on the mesh.
A representation which explicitly stores
every entity is said to be a {\it full}
representation.
Any schemes which allow some entities to be represented
implicitly (i.e. their presence does not consume memory)
are {\it reduced} representations.

As we began to discuss in Section \ref{sec:def_adapt},
there are multiple factors in the decision of which entities to store:
\begin{enumerate}
\item For boundary condition application, it is necessary to
be able to infer the classification of mesh faces.
\item For mesh adaptivity, it is necessary to be able to
infer the classification of any mesh entity, whether stored or not.
\item In mesh adaptation, it is often useful to store values
on the edges and vertices (for example, booleans indicating they
are candidates for modification).
\item If the basis functions used for PDE discretization have
degrees of freedom on edges or faces, those edges and faces
must be stored.
\end{enumerate}

There are also many consequences of storing only a subset of entities that
must be considered:
\begin{enumerate}
\item If some entities of a given dimension are not stored, then
downward adjacencies from a higher dimension to the partially-stored dimension
would need to be more complex.
\begin{enumerate}
\item Given a single high-dimensional entity, the ordering of its
adjacent bounding entities is crucial.
If some of them are not stored, the remaining adjacency relationships
would need to be annotated with ordering information such that the correct
ordering can still be reconstructed.
\item Depending on the implementation, downward adjacencies would either
not have constant degree of have ``null" values where non-stored entities
are adjacent.
Both would complicate all code that queries and manages
downward adjacencies.
\end{enumerate}
\item How to query information (such as classification) about a non-stored
entity is unclear. FMDB took the approach of temporarily creating
and storing those entities when queries were made \cite{seol2006efficient}.
Celes, Paulino, and Espinha use a similar solution in their reduced
representation \cite{celes2005compact}.
This workaround is incompatible with portable execution, as GPUs
would not allow creating entities individually in this manner.
\end{enumerate}
Beall and Shephard indicate other complexities involved
with handling reduced representations \cite{beall1997general}.

Given that adaptation would require us to store edges and boundary
faces, we are left only considering whether to introduce great
complexity in exchange for not storing interior faces.
In this work we choose instead to store all entities.

\subsection{Choosing Adjacencies to Store}

Once the set of explicit entities is chosen, one has
options about which adjacencies to store.
Recall from Section \ref{sec:def_adj} that downward and upward
adjacencies are transitive, so there are many
subsets of the adjacencies from which the others
can be reconstructed.
For any given representation, the computation of $M^d_i\{M^q\}$
can either be done efficiently using stored information
or using an exhaustive search if less information is available.
If one can compute $M^d_i\{M^q\}$ for a single
given entity $M^d_i$ in constant time,
we say that the stored information is {\it complete} \cite{seol2006efficient}.
Recall from Section \ref{sec:def_fem} that upward adjacencies
are bound by a constant, so they are computable in
constant-time if enough information is stored.

A comparison of representations based on the choice
of dimensions and adjacencies between
dimensions to represent
was published by Garimella \cite{garimella2002mesh}.
The choices we made in our structures are described separately
for each data structure,
in Sections \ref{sec:mds_adj} and \ref{sec:adj_cache}.

\section{MDS Data Structure}
\label{sec:sisc}

{\bf SISC attribution}

The MDS structure is built around the following key characteristics:

\begin{enumerate}
\item The representation centers around graph theoretic interpretations
of topological adjacency.
\item The mesh can remain topologically consistent with and associated with
geometric model entities.
\item The common element types of FE/FV methods can coexist in one structure.
\item Additional data can be associated with entities to implement
high order basis functions, including for geometric approximation.
\item A mesh can be modified by adding and removing single entities in constant time.
\item The entire mesh is stored in a few contiguous dynamic arrays.
\end{enumerate}

One key contribution of this thesis is to show that the latter two properties,
array storage and rapid single-entity modification, are not mutually exclusive
and can be combined in a viable way.

\subsection{Adjacencies stored in MDS}
\label{sec:mds_adj}

MDS is based on the full {\it one-level} representation,
in which we store the upward
and downward adjacencies between each consecutive
pair of dimensions \cite{beall1997general}.
In particular, it stores
region-face, face-edge, and edge-vertex adjacencies
(both upward and downward).
Despite this focus on the one-level adjacencies, the general MDS
structure can be used to store any subset of
adjacency relations.

\begin{figure}
\begin{center}
\includegraphics[width=0.53\textwidth]{full_rep.png}
\quad
\includegraphics[width=0.15\textwidth]{adjs_mds.png}
\caption{(left) a geometric representation of one-level
relations among a subset of the entities that bound a tetrahedron.
(right) simpler depiction of one-level relations between dimensions}
\label{fig:topo}
\end{center}
\end{figure}

Figure \ref{fig:topo} illustrates the relationships
stored in a full one-level representation.
Each arrow representing an adjacency relation (a.k.a. entity use)
is bi-directional to indicate that we store both the
downward (high to low dimension) and upward (low to high) relations.
Note that vertices are related only to edges,
regions are related only to faces, etc.

Downward adjacencies not directly stored are derived
locally by intersecting existing adjacencies.
For example, the vertices of a triangle may be found
by querying its edges and then the vertices of those
edges, and ordering is preserved by finding a vertex
that is adjacent to two particular edges.
Such intersection logic moves down one dimension, and
can be repeated if needed.

Conversely, upward adjacencies are found by successive
unions of existing adjacencies.
Given a vertex, one can retrieve adjacent edges, then
for each edge retrieve adjacent faces, then take the
union of these sets of faces, giving the set of unique
faces adjacent to the edge.

\subsection{Object-Oriented Storage}
\label{sec:sisc_oo}

We begin by describing how our structure would look
if we stored it in an object-oriented manner.
In object-oriented programming, data is organized
into {\it objects} of a few {\it types}.
All objects of the same type have the same {\it attributes},
and for each object and associated attribute a {\it value} must be stored.
In the present case, the objects are mesh topological entities
and the attributes are pointers encoding adjacency relations.

The goal is to organize all data into objects whose
sizes are known at compile time based on their type.
The first step to doing this is to create separate object types
based on topological type.
Objects of the same type are all topologically similar to some polytope,
for example a triangle or a pyramid.
This ensures that their downward adjacency degrees are all the same,
which makes downward adjacency storage fairly straightforward.
For example, a tetrahedron in a full representation would store
four pointers to its bounding faces.

\begin{figure}
\begin{center}
\includegraphics[width=0.9\textwidth]{oo.png}
\caption{(left) the example mesh: a reduced representation of two
triangles sharing one edge and two vertices.
(middle) the linked-list storage of upward adjacency information
for vertices to triangles.
(right) a key describing the meaning of symbols in the middle figure}
\label{fig:oo}
\end{center}
\end{figure}

The second step is to use a linked-list technique \cite{karamete2016novel}
to distribute upward-adjacency storage amongst the entities
of higher dimension, alleviating the need for variable-length
storage in lower-dimensional objects.
If an object stores $m$ downward pointers, then it also stores
$m$ singly-linked list nodes.
A singly-linked list node simply contains a pointer to the next
node, which can also be null.
Every low-dimensional object then stores a single ``head" node
which begins their upward linked list.
If a high-dimensional object ($h$) points to a low-dimensional object ($l$)
from its $j$th downward pointer, then its $j$th list node must be
part of object $l$'s linked list.
Figure \ref{fig:oo} illustrates this portion of the data structure
for a reduced mesh of two triangles.
Notice how, for a shared vertex, one begins at the vertex's head node,
reaches a node that is stored for triangle 0, then continues
to a node stored for triangle 1, which contains a null pointer.
This is fundamentally how upward adjacency is queried for a vertex.
A singly-linked list can be used as opposed to doubly-linked one
because per Section \ref{sec:def_mesh}
the number of nodes in this list has a constant upper bound.
This means we can afford the $O(m)$ runtime cost of removing a node from this
list when a high-dimensional entity is removed
($m$ being the number of upward adjacent entities),
in exchange for halving the memory use.

\subsection{Structure of Arrays}
\label{sec:sisc_soa}

Next we describe how we convert the object-oriented structure
into an array-based one.
Instead of storing all data for a single object contiguously,
i.e. organizing by object first and then by attribute,
we organize data first by attribute and then by object.
We store all data for a single attribute in a contiguous
array, hence this scheme can be called a {\it structure of arrays}
\cite{sung2012dl}.
In our case, examples of attribute arrays would be
the ``first up" nodes for all entities of dimension $d$
and likewise the ``next up" nodes for all entities of dimension $(d+1)$.
For a static mesh we would be done, but this structure needs
to support efficient addition and removal of objects.
We therefore need to manage the arrays which store attributes
for all objects a single type, to account for addition and removal
of objects of that type.

When users request the addition of a new entity, we are allowed
to store it anywhere in the structure.
In this case adding objects in constant time has a well-known
solution called geometric growth \cite{cormen2001table}.
At any time we have some amount of array storage capacity $c(t)$
which is filled entry at a time.
When that storage is full, we reallocate it to a new capacity $c(t+1)$,
such that the integer function $c(t)$ approximates the real function
$f(t) = \alpha^t$, where $1< \alpha\leq 2$.
Although reallocation has a runtime cost of $O(c(t))$, the geometric
growth amortizes this cost such that adding objects
is constant-time on average \cite{cormen2001table}.
The tradeoff is that a bounded fraction of the storage is unused extra space.
In our case, we use a growth formula of $c(t+1) = (3(c(t)+1))/2$
as a heuristic compromise between memory and runtime.

Removing objects is usually the more troublesome operation for
array-based structures.
First, we have no control over which object is being removed.
This means a ``hole" will be created at some arbitrary index.
While some implementations opt to fill this hole immediately
with an existing object, we will avoid this because it requires
changing the index of a live object,
which causes great confusion to users
and leads to programming errors.
We prefer that object indices are like object pointers: constant
throughout the lifetime of the object.
This way a handle/pointer/index may be maintained by the user
and it will have clear meaning even during mesh modification.

If we cannot change indices then the holes must remain, and
we will track them using a free list, or list of available
space \cite{knuth1997list}.
In our implementation, this means creating a new variable array
along with those of the objects.
This array which we call the free list contains pointers
from each hole to the next hole,
and a single head pointer outside this list
points to the first hole.
We can use a singly-linked list efficiently by adding and
removing holes only to and from the front of this list,
both of which are constant-time operations.

In summary, to add an object, we first check whether there
are holes in the free list.
If so, the first hole is used as space for the object,
and it is removed from the free list.
Otherwise the object is added at the end,
which may trigger a geometric growth of all arrays
simultaneously.
To remove an object, we simply add the resulting hole as the first hole
in the free list.
See Figure \ref{fig:flex} for a helpful layout diagram
of modifiable object arrays.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{flex.png}
\caption{Extra space and hole tracking create modifiable arrays}
\label{fig:flex}
\end{center}
\end{figure}

One issue with this structure is that memory use does
not decrease immediately when removing objects, and in theory we can
only shrink the arrays if the last object is removed.
This is connected to our decision to preserve identifiers,
and can be fixed by temporarily relaxing that constraint.
In a single collective step, all objects can be reordered,
given new identifiers, and all links between them updated
accordingly.
If the new identifiers are contiguous, the arrays can shrink
to minimal size.
Beyond that, we can choose a reordering which
makes subsequent queries cache-friendly.
Beall and Shephard describe a reordering for mesh entities which
improves the locality of subsequent adjacency queries
and, more importantly, the sparsity pattern of
matrices assembled from finite element meshes \cite{beall1997general}.
Adjacency-based reordering was expanded upon and
tested by Zhou et al. \cite{zhou2010adjacency}.
This is a supported operation in our implementation,
which combines hole removal with adjacency-based reordering
that improves locality.

An important benefit of this array-based structure is the
ease with which additional attributes can be added or removed
at runtime.
To add a new attribute to objects of the same type, we just
create a new array and ensure that subsequent resizing
operations apply to that array along with the others.
For example, different simulations may require different
attributes such as position, velocity, mass, and electrical charge.
These can each be allocated as a separate array,
and each can be added and removed at runtime as needed
with essentially no memory overhead.

\subsection{Lists in Arrays}
\label{sec:lia}

Since our initial structure composed of many small objects containing pointers
to one another was recast into a set of large arrays
as opposed to individually allocated objects,
pointers to objects get transformed into array indices.
As an example, consider the transformation for a singly-linked
list as shown in Figure \ref{fig:arraylist}.

All the list nodes are packed into an array, and a pointer to
a list node becomes an index into this array, starting with zero.
Since zero is a valid index, we can use -1 to denote a null pointer.
Notice also that if we have knowledge about the maximum length
of the array, we can choose an integer type that uses less bytes
than a pointer, since pointers must be able to index the entire
virtual address space.

\begin{figure}
\begin{center}
\includegraphics[width=0.6\textwidth]{arraylist.png}
\caption{(left) A linked list in object form, each node containing
a memory address pointer to the next node.
(right) The same linked list packed into an array.
The data contained inside each node is the array index of the next node.
Underneath each node, its own index is indicated.
The letters serve to indicate corresponding nodes before and after.}
\label{fig:arraylist}
\end{center}
\end{figure}

Since indices can have the same meaning for several arrays,
we can separate the variables in an object into different
arrays.

\subsection{Dynamically Modifiable Mesh Structure}
\label{sec:sisc_mstruct}

\begin{figure}
\begin{center}
\includegraphics[width=0.95\textwidth]{mixed.png}
\caption{(left) an example subset of a mixed mesh:
an edge adjacent to a triangle and a quad.
(right) the corresponding upward adjacency linkage
must traverse separate triangle and quad arrays.}
\label{fig:mixed}
\end{center}
\end{figure}

There is one more detail that needs resolving in the
case of mixed meshes.
The problem is that different polytope
groups may contain uses of the same entity.
For example, an edge may be used by a triangle and a quadrilateral.
They must be linked together, but their arrays are
separated by polytope group.
In order to be able to jump between those arrays, we must
enhance the indices being used.
Our solution is to encode information about the polytope group
into these indices, i.e. $e = (t,i)$ where $t$ is an integer
uniquely identifying a polytope group, $i$ is the index
into the arrays of that group, and $e$ is the extended index.
In particular, the encoding we choose is $e = iT + t$, where
$T$ is the total number of polytope groups and $0\leq t < T$.
This allows the extended index to remain an integer
and be decoded using simple modulo and division instructions.
Figure \ref{fig:mixed} illustrates this representation.
Starting with entry $20$ in the ``edge first up" array,
we are directed to edge use $2$ of quad $10$.
At entry $i=(10\cdot 4 + 2)$ of the ``quad next up" array,
we are further directed to edge use $0$ of triangle $4$.
At entry $i=(4\cdot 3 + 0)$, we find a null pointer and stop.

To get clear picture of all the arrays and their groupings
that are allocated for a real mesh, here is a listing
including all polytope types that a complex CFD mesh
might need when boundary layers are constructed with
a mix of wedges and pyramids:

\begin{enumerate}
\item Vertices
  \begin{enumerate}
  \item Coordinates (size $=3\times$vertex capacity)
  \item First edge (size $=$vertex capacity)
  \item Free list (size $=$vertex capacity)
  \end{enumerate}
\item Edges
  \begin{enumerate}
  \item Vertices used (size $=2\times$edge capacity)
  \item Next edge up (size $=2\times$edge capacity)
  \item First face up (size $=$edge capacity)
  \item Free list (size $=$edge capacity)
  \end{enumerate}
\item Triangles
  \begin{enumerate}
  \item Edges used (size $=3\times$triangle capacity)
  \item Next face up (size $=3\times$triangle capacity)
  \item First region up (size $=$triangle capacity)
  \item Free list (size $=$triangle capacity)
  \end{enumerate}
\item Quadrilaterals
  \begin{enumerate}
  \item Edges used (size $=4\times$quadrilateral capacity)
  \item Next face up (size $=4\times$quadrilateral capacity)
  \item First region up (size $=$quadrilateral capacity)
  \item Free list (size $=$quadrilateral capacity)
  \end{enumerate}
\item Tetrahedra
  \begin{enumerate}
  \item Faces used (size $=4\times$tetrahedra capacity)
  \item Next region up (size $=4\times$tetrahedra capacity)
  \item Free list (size $=$tetrahedra capacity)
  \end{enumerate}
\item Wedges
  \begin{enumerate}
  \item Faces used (size $=5\times$wedges capacity)
  \item Next region up (size $=5\times$wedges capacity)
  \item Free list (size $=$wedges capacity)
  \end{enumerate}
\item Pyramids
  \begin{enumerate}
  \item Faces used (size $=5\times$pyramid capacity)
  \item Next region up (size $=5\times$pyramid capacity)
  \item Free list (size $=$pyramid capacity)
  \end{enumerate}
\end{enumerate}
Where the capacities refer to the geometric growth
capacity described in Section \ref{sec:sisc_soa} based
on the current number of entities of that polytope group.

This structure provides a straightforward mechanism for associating
data with each entity of a polytope group by creating
new arrays as described in Section \ref{sec:sisc_soa}.
This is how vertex coordinates and entity-level fields
are stored.

\section{Omega\_h Data Structure}
\label{sec:omega_h-struct}

{\bf this is from the full-paper IMR submission}

{\bf a bit more intro describing the difference
versus MDS}

Among the many restrictions of GPU programming
is that memory allocation within the GPU threads is strongly
discouraged, or is not possible.
This implies that allocations must be made large enough
that a single CPU thread can handle their allocation and de-allocation.
Combine this with the GPU parallelism model of having each
thread handle a simple task corresponding to an array index, and
it is clear that arrays are the optimal choice of data structure.

{\bf also need to mention that contention free list
heads and growth prevent us from using MDS structure
with on-node threading}

Our implementation uses array structures similar to those
of the original MOAB mesh database \cite{tautges2004moab},
and also of several solvers which implement their own structures.
We assume that either all elements are tetrahedra or they are all triangles.
This allows us to store downward adjacencies in a single array
that can be thought of as two-dimensional.
Upward adjacencies are stored in the widely known compressed row format,
used for example in the METIS interface \cite{METIS}.
We do store a full mesh representation \cite{beall1997general}, meaning
that all faces and edges are also stored.
We need at least the boundary faces and edges to robustly preserve
topology, and storing all mesh entities simplifies data structures
and algorithms.

\begin{figure}[t]\vspace*{4pt}
\caption{{\bf THIS NEEDS TO BE REDONE} Permanent (solid arrow) and on-demand (dashed arrow) adjacencies}\vspace*{-6pt}
\label{fig:adjs}
\end{figure}

\subsection{Adjacency Cache}
\label{sec:adj_cache}

The majority of adaptation time and memory is consumed by the
derivation and storage of mesh adjacencies.
To mitigate the runtime cost, our mesh structure acts as an adjacency cache,
which derives new adjacencies when they are requested and stores
them in case of later requests.
Figure \ref{fig:adjs} shows the adjacencies that we start with and some
that are derived.
By default, all entities are defined by their downward adjacency to mesh vertices.
This is the only adjacency data that mesh adaptation code has to rebuild
directly.
Other adjacencies are inferred from the vertex adjacencies.

We use two forms of adjacency inference:
\begin{enumerate}
\item Inversion: an upward adjacency is derived from is corresponding downward
adjacency. This reduces to a low-degree graph inversion problem, which we
solve either by sorting graph edges by their destination graph node or using
atomic operations to associate graph edges with their destination graph nodes.
\item Reflection: a downward adjacency from dimension $a$ to dimension $b$
is derived by combining the adjacencies from $a$ to vertices and from
vertices back to $b$.
Seeking a subset of the vertices of $a$, we explore all $b$-dimension entities
adjacent to the first vertex and check whether any of them have all the
desired vertices.
\item Transiting: {\bf TODO: describe this}
\end{enumerate}

{\bf TODO: describe why using one-level is better than going to vertices}

\subsection{Alignment Codes}

\section{Data Structure Performance}

{\bf Query times, modification times, etc. for both structures.}

\subsection{Adjacency Query Performance}

To substantiate our claims of $O(1)$ adjacency queries and
give an example of typical query performance, we create two
uniform meshes at different resolutions, having approximately
100K and 200K elements, respectively.
We then time, for each pair of dimensions, how long it takes
to traverse all entities of the first dimension and query their
adjacent entities of the second dimension.
The time required to do this should be approximately the number
of entities of the first dimension times the constant time
required for one adjacency query.
Tables \ref{tab:mds_adj_100} and \ref{tab:mds_adj_200} list these timing
results for both meshes, and show fairly clearly that all times
grow by about 2X since the number of elements is about 2X larger
in the second mesh.
These timings were collected on a workstation with an Intel Xeon E5-2620v4 CPU.

\begin{table}
\caption{MDS adjacency timings (in milliseconds) for 100K tet mesh}
\label{tab:mds_adj_100}
\begin{center}
\begin{tabular}{l|r|}
dimension & entity count \\\hline
0 & 19468 \\
1 & 129010 \\
2 & 212846 \\
3 & 103303 \\
\end{tabular}
\begin{tabular}{|r|r|r r r r}
               &   & \multicolumn{4}{c}{to dimension} \\\hline
               &   &    0 &    1 &    2 &   3  \\\hline
               & 0 &      &  3.9 & 48.7 & 88.9 \\
               & 1 &  2.4 &      & 11.9 & 40.4 \\
from           & 2 & 16.2 &  4.2 &      &  9.0 \\
dimension      & 3 & 21.1 & 13.1 &  2.2 &      \\
\end{tabular}
\end{center}
\end{table}

\begin{table}
\caption{MDS adjacency timings (in milliseconds) for 200K tet mesh}
\label{tab:mds_adj_200}
\begin{center}
\begin{tabular}{l|r|}
dimension & entity count \\\hline
0 & 39696  \\
1 & 265267 \\
2 & 439107 \\
3 & 213535 \\
\end{tabular}
\begin{tabular}{|r|r|r r r r}
               &   & \multicolumn{4}{c}{to dimension} \\\hline
               &   &    0 &    1 &     2 &     3 \\\hline
               & 0 &      &  8.7 & 104.8 & 191.5 \\
               & 1 &  5.0 &      &  26.3 &  84.7 \\
from           & 2 & 33.4 &  8.7 &       &  20.3 \\
dimension      & 3 & 45.6 & 27.8 &   4.5 &       \\
\end{tabular}
\end{center}
\end{table}

Because Omega\_h uses an adjacency cache, the runtime cost
of querying a particular adjacency depends on which adjacencies
are already cached at the moment.
In the trivial case, that adjacency is already cached and
need only be read directly from memory.
This trivial case is illustrated in Table \ref{tab:osh_walk_100},
showing the time required to simply read and traverse cached adjacency
information from memory, for all entities of a given dimension,
using the same 100K mesh as Table \ref{tab:mds_adj_100}.
Table \ref{tab:osh_adj_100} then presents incremental construction
times, i.e. the time required to construct an adjacency
(for all entities of the relevant dimension)
assuming any pre-requisite adjacencies used in the construction
have already been cached.

\begin{table}
\caption{Omega\_h traversal timings (in milliseconds) for 100K tet mesh}
\label{tab:osh_walk_100}
\begin{center}
\begin{tabular}{|r|r|r r r r}
               &   & \multicolumn{4}{c}{to dimension} \\\hline
               &   &    0 &    1 &    2 &   3  \\\hline
               & 0 &      &  0.2 &  0.2 &  0.2 \\
               & 1 &  1.7 &      &  1.4 &  1.4 \\
from           & 2 &  2.6 &  2.7 &      &  2.3 \\
dimension      & 3 &  1.2 &  1.2 &  1.3 &      \\
\end{tabular}
\end{center}
\end{table}

\begin{table}
\caption{Omega\_h incremental construction timings (in milliseconds) for 100K tet mesh}
\label{tab:osh_adj_100}
\begin{center}
\begin{tabular}{|r|r|r r r r}
               &   & \multicolumn{4}{c}{to dimension} \\\hline
               &   &    0 &    1 &    2 &   3  \\\hline
               & 0 &      &  7.6 & 31.1 & 16.1 \\
               & 1 &      &      & 11.1 &  9.7 \\
from           & 2 &  5.5 &      &      &  4.7 \\
dimension      & 3 &  3.2 &  9.1 &      &      \\
\end{tabular}
\end{center}
\end{table}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
