%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                 %
%                            CHAPTER THREE                        %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{DISTRIBUTED AND SHARED MEMORY PARALLELISM}

\section{Distributed Memory Parallelism}

\subsection{Scalability}

\subsubsection{Goals}

\begin{equation} \label{eq:big-o-scale}
t = O(\frac{N}{P}\lg(P))
\end{equation}

\subsubsection{Requirements}

A list of requirements for scalability:

\begin{enumerate}
\item Never collect data of size $O(P)$ on one processor
\end{enumerate}

\subsection{Distributor}

This is a key system for exchanging data, i.e.
the equivalent of PCU in a more array-based setting.

\subsection{Ownership}

Discuss our ownership system, compare/contrast to
others especially PUMI/FMDB.

\subsection{Migration}

Describe the "pull" versus "push" methodologies and
how one more naturally supports ghosting.

\subsection{Ghosting}

\subsection{Load Balancing}

\subsubsection{Recursive Inertial Bisection}

\section{Independent Set of Cavities}

\subsection{Shared Memory Selection}

\subsection{Distributed Memory Selection}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

